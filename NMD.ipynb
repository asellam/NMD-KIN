{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neighborhood Min Distance (NMD) descriptor routines</h1>\n",
    "<h1>get_batch_nmd</h1>\n",
    "This function calculates the Neighborhood Min Distance (NMD) descriptor from two batches of images. This function is used by the get_nmd function for memory effeciency if the data is too large.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>P</h5>\n",
    "A 4D numpy array containing the batch of facial images of parents.\n",
    "<br><b>Shape:</b> (NumberOfImages, Height, Width, NumberOfChannels)\n",
    "\n",
    "<h5>C</h5>\n",
    "A 4D numpy array containing the batch of facial images of children.\n",
    "<br><b>Shape:</b> (NumberOfImages, Height, Width, NumberOfChannels)\n",
    "\n",
    "<h5>N</h5>\n",
    "The width and height (size) of the NMD patch (neighborhood).\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A 2D numpy array containing the NMD descriptors of all pairs from batches P and C.\n",
    "<br><b>Shape:</b> (NumberOfImages, (Height-N+1) &#215; (Width-N+1))\n",
    "\n",
    "<h3>Notes</h3>\n",
    "The NumberOfImages, Height, Width, and NumberOfChannels of parents and children images must be identical to each other.\n",
    "\n",
    "<h1>get_nmd</h1>\n",
    "This function calculates the Neighborhood Min Distance (NMD) descriptor from two sets of images.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>P</h5>\n",
    "A 4D numpy array containing the set of facial images of parents.\n",
    "<br><b>Shape:</b> (NumberOfImages, Height, Width, NumberOfChannels)\n",
    "\n",
    "<h5>C</h5>\n",
    "A 4D numpy array containing the set of facial images of children.\n",
    "<br><b>Shape:</b> (NumberOfImages, Height, Width, NumberOfChannels)\n",
    "\n",
    "<h5>N</h5>\n",
    "The width and height (size) of the NMD patch (neighborhood).\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A 2D numpy array containing the NMD descriptors of all pairs from sets P and C.\n",
    "<br><b>Shape:</b> (NumberOfImages, (Height-N+1) &#215; (Width-N+1))\n",
    "\n",
    "<h3>Notes</h3>\n",
    "The NumberOfImages, Height, Width, and NumberOfChannels of parents and children images must be identical to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "def get_batch_nmd(P, C, N):\n",
    "    h = N // 2\n",
    "    assert P.shape == C.shape\n",
    "    CropP = P[:, h:-h, h:-h, :]\n",
    "    Dists = np.empty((N*N, P.shape[0], P.shape[1]-N+1, P.shape[2]-N+1))\n",
    "    p = 0\n",
    "    for i in range(-h, h+1):\n",
    "        for j in range(-h, h+1):\n",
    "            i0, i1 = i+h, C.shape[1]+i-h\n",
    "            j0, j1 = j+h, C.shape[2]+j-h\n",
    "            CropC = C[:, i0:i1, j0:j1, :]\n",
    "            Dists[p, :, :, :] = np.sum(np.square(CropP-CropC), axis=3)\n",
    "            p = p + 1\n",
    "    NMD3D = np.min(Dists, axis=0)\n",
    "    NMD = np.empty((NMD3D.shape[0],NMD3D.shape[1]*NMD3D.shape[2]))\n",
    "    for p in range(NMD3D.shape[0]):\n",
    "        NMD[p, :] = NMD3D[p].flatten()\n",
    "    return NMD\n",
    "\n",
    "def get_nmd(P, C, N):\n",
    "    assert P.shape == C.shape\n",
    "    NMD = np.empty((P.shape[0],(P.shape[1]-N+1)*(P.shape[2]-N+1)))\n",
    "    for batch in range(0, P.shape[0], batch_size):\n",
    "        size = min(batch_size, P.shape[0]-batch)\n",
    "        NMD[batch:batch+size, :] = get_batch_nmd(P[batch:batch+size, :, :, :], C[batch:batch+size, :, :, :], N)\n",
    "    return NMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kinship data loading routines</h1>\n",
    "<h1>load_txt_pairs</h1>\n",
    "Loads kinship pairs from a text file following our encoding in which each line in the text file corresponds to a single pair and has the following format:\n",
    "\n",
    "fold_number kinship_label parent_image_file_name child_image_file_name\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>filename</h5>\n",
    "A string indicating the path to the pairs text file.\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A list of pairs, each pair is a tuple of four elements corresponding to:\n",
    "\n",
    "<ol>\n",
    "    <li> The fold number </li>\n",
    "    <li> The kinship label </li>\n",
    "    <li> The file name of the parent image </li>\n",
    "    <li> The file name of the child image </li>\n",
    "</ol>\n",
    "\n",
    "<h1>load_mat_pairs</h1>\n",
    "Loads kinship pairs from a matlab variable file following KinFaceW schema.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>filename</h5>\n",
    "A string indicating the path to the pairs matlab variable file.\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A list of pairs, each pair is a tuple of four elements corresponding to:\n",
    "\n",
    "<ol>\n",
    "    <li> The fold number </li>\n",
    "    <li> The kinship label </li>\n",
    "    <li> The file name of the parent image </li>\n",
    "    <li> The file name of the child image </li>\n",
    "</ol>\n",
    "\n",
    "<h1>get_image_dirs</h1>\n",
    "Gives the directories containing the facial images of parents and children.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>rootdir</h5>\n",
    "A string indicating the path of the directory containing all kinship datasets.\n",
    "\n",
    "<h5>dataset</h5>\n",
    "A string indicating the name of the kinship dataset, must be one of these values: 'KinFaceW-I', 'KinFaceW-II', or 'CornellKinFace'.\n",
    "\n",
    "<h5>subset</h5>\n",
    "A string indicating the name of the kinship subset, unused with the CornellKinFace dataset, must be one of these values with the KinFaceW datasets: 'fs', 'fd', 'ms', or 'md'.\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A tuple containing the pathes of the parents image-directory and the children image-directory.\n",
    "\n",
    "<h1>load_pairs</h1>\n",
    "Loads the kinship pairs from the meta file of a dataset.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>rootdir</h5>\n",
    "A string indicating the path of the directory containing all kinship datasets.\n",
    "\n",
    "<h5>dataset</h5>\n",
    "A string indicating the name of the kinship dataset, must be one of these values: 'KinFaceW-I', 'KinFaceW-II', or 'CornellKinFace'.\n",
    "\n",
    "<h5>subset</h5>\n",
    "A string indicating the name of the kinship subset, unused with the CornellKinFace dataset, must be one of these values with the KinFaceW datasets: 'fs', 'fd', 'ms', or 'md'.\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A list of pairs, each pair is a tuple of four elements corresponding to:\n",
    "\n",
    "<ol>\n",
    "    <li> The fold number </li>\n",
    "    <li> The kinship label </li>\n",
    "    <li> The file name of the parent image </li>\n",
    "    <li> The file name of the child image </li>\n",
    "</ol>\n",
    "\n",
    "<h1>load_fold</h1>\n",
    "Loads the kinship data from one fold of a certain dataset.\n",
    "\n",
    "<h3>Parameters</h3>\n",
    "\n",
    "<h5>rootdir</h5>\n",
    "A string indicating the path of the directory containing all kinship datasets.\n",
    "\n",
    "<h5>dataset</h5>\n",
    "A string indicating the name of the kinship dataset, must be one of these values: 'KinFaceW-I', 'KinFaceW-II', or 'CornellKinFace'.\n",
    "\n",
    "<h5>subset</h5>\n",
    "A string indicating the name of the kinship subset, unused with the CornellKinFace dataset, must be one of these values with the KinFaceW datasets: 'fs', 'fd', 'ms', or 'md'.\n",
    "\n",
    "<h5>fold</h5>\n",
    "The number of fold to load depending on the meta-data (list of pairs) of the dataset.\n",
    "\n",
    "<h3>Return Value</h3>\n",
    "\n",
    "A tuple containing the following:\n",
    "\n",
    "<ol>\n",
    "    <li> \n",
    "        A tuple containing the training data: \n",
    "        <ol>\n",
    "            <li> <b>The parents images:</b> A numpy array of shape (NumberOfImages, Height, Width, NumberOfChannels) </li>\n",
    "            <li> <b>The children images:</b> A numpy array of shape (NumberOfImages, Height, Width, NumberOfChannels) </li>\n",
    "            <li> <b>The kinship labels:</b> A numpy array of shape (NumberOfImages, 1) </li>\n",
    "        </ol>\n",
    "    </li>\n",
    "     <li> \n",
    "        A tuple containing the test data: \n",
    "        <ol>\n",
    "            <ol>\n",
    "            <li> <b>The parents images:</b> A numpy array of shape (NumberOfImages, Height, Width, NumberOfChannels) </li>\n",
    "            <li> <b>The children images:</b> A numpy array of shape (NumberOfImages, Height, Width, NumberOfChannels) </li>\n",
    "            <li> <b>The kinship labels:</b> A numpy array of shape (NumberOfImages, 1) </li>\n",
    "        </ol>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def load_txt_pairs(filename):\n",
    "    metafile = open(filename, 'r')\n",
    "    metadata = metafile.read()\n",
    "    metafile.close()\n",
    "    metalines = [line for line in metadata.split('\\n') if len(line)>0]\n",
    "    str_pairs = [metaline.split(' ') for metaline in metalines]\n",
    "    pairs = [[int(pair[0]), int(pair[1]), pair[2], pair[3]] for pair in str_pairs]\n",
    "    return pairs\n",
    "\n",
    "def load_mat_pairs(filename):\n",
    "    meta = sio.loadmat(filename)\n",
    "    pairs = []\n",
    "    for p in meta['pairs']:\n",
    "        pairs.append([p[0][0][0], p[1][0][0], p[2][0], p[3][0]])\n",
    "    return pairs\n",
    "\n",
    "def get_image_dirs(rootdir, dataset, subset):\n",
    "    PrefixToDir={'fd':'father-dau','fs':'father-son','md':'mother-dau','ms':'mother-son'}\n",
    "    if dataset[:10]=='KinFaceW-I':\n",
    "        same_dir = join(rootdir, dataset, 'images', PrefixToDir[subset])\n",
    "        return (same_dir, same_dir)\n",
    "    if dataset=='CornellKinFace':\n",
    "        parents_dir = join(rootdir, dataset, 'Parents')\n",
    "        children_dir = join(rootdir, dataset, 'Children')\n",
    "        return (parents_dir, children_dir)\n",
    "    return None\n",
    "\n",
    "def load_pairs(rootdir, dataset, subset):\n",
    "    if dataset=='KinFaceW-I' or dataset=='KinFaceW-II':\n",
    "        return load_mat_pairs(join(rootdir, dataset, 'meta_data', subset + '_pairs.mat'))\n",
    "    if dataset=='CornellKinFace':\n",
    "        return load_txt_pairs(join(rootdir, dataset, 'cornell-meta.txt'))\n",
    "    return None\n",
    "\n",
    "def load_fold(rootdir, dataset, subset, fold):\n",
    "    pairs = load_pairs(rootdir, dataset, subset)\n",
    "    image_dirs = get_image_dirs(rootdir, dataset, subset)\n",
    "    P0, C0, K0 = [], [], []\n",
    "    P1, C1, K1 = [], [], []\n",
    "    for p in pairs:\n",
    "        pImg = imread(join(image_dirs[0], p[2])) / 255\n",
    "        cImg = imread(join(image_dirs[1], p[3])) / 255\n",
    "        if p[0] == fold:\n",
    "            P1.append(pImg)\n",
    "            C1.append(cImg)\n",
    "            K1.append(p[1])\n",
    "        else:\n",
    "            P0.append(pImg)\n",
    "            C0.append(cImg)\n",
    "            K0.append(p[1])\n",
    "    return ((np.array(P0), np.array(C0), np.array(K0)), (np.array(P1), np.array(C1), np.array(K1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> The NMD experiments</h1>\n",
    "You must change line #4 indicating the path to the directory containing all kinship datasets.\n",
    "\n",
    "Line #6 specifies the different datasets to experiment on.\n",
    "\n",
    "Line #16 specifies the SVM grid search parameters.\n",
    "\n",
    "Lines #17 and #18 specify the Random Forest grid search parameters.\n",
    "\n",
    "Lines #26 and #27 calculate the training and test NMD descriptors, you may want to change the third parameter indicating the NMD patch-size.\n",
    "\n",
    "<h3> Notes </h3>\n",
    "Because the <b>Random Forest</b> classifier has an incorporated random process in it, the results may change each time it's executed. To overcome this you can add a loop that performs serveral trials for each fold and report the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CornellKinFace all\n",
      "SVM: 71.58% [nu: 0.4]\n",
      "RandomForest: 77.97% [max_depth: 13] [n_estimators: 5]\n",
      "KinFaceW-I fs\n",
      "SVM: 67.30% [nu: 0.7]\n",
      "RandomForest: 72.14% [max_depth: 11] [n_estimators: 5]\n",
      "KinFaceW-I fd\n",
      "SVM: 59.36% [nu: 0.8]\n",
      "RandomForest: 69.03% [max_depth: 11] [n_estimators: 4]\n",
      "KinFaceW-I ms\n",
      "SVM: 65.09% [nu: 0.55]\n",
      "RandomForest: 75.02% [max_depth: 12] [n_estimators: 5]\n",
      "KinFaceW-I md\n",
      "SVM: 72.81% [nu: 0.4]\n",
      "RandomForest: 84.64% [max_depth: 11] [n_estimators: 4]\n",
      "KinFaceW-II fs\n",
      "SVM: 79.80% [nu: 0.35]\n",
      "RandomForest: 88.00% [max_depth: 14] [n_estimators: 5]\n",
      "KinFaceW-II fd\n",
      "SVM: 74.80% [nu: 0.5]\n",
      "RandomForest: 81.80% [max_depth: 12] [n_estimators: 5]\n",
      "KinFaceW-II ms\n",
      "SVM: 79.80% [nu: 0.4]\n",
      "RandomForest: 90.00% [max_depth: 11] [n_estimators: 5]\n",
      "KinFaceW-II md\n",
      "SVM: 86.40% [nu: 0.3]\n",
      "RandomForest: 92.00% [max_depth: 10] [n_estimators: 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "\n",
    "rootdir = 'D:/PhD/DataSets'\n",
    "\n",
    "datasets = [('CornellKinFace', 'all', 5),\n",
    "            ('KinFaceW-I', 'fs', 5),\n",
    "            ('KinFaceW-I', 'fd', 5),\n",
    "            ('KinFaceW-I', 'ms', 5),\n",
    "            ('KinFaceW-I', 'md', 5),\n",
    "            ('KinFaceW-II', 'fs', 5),\n",
    "            ('KinFaceW-II', 'fd', 5),\n",
    "            ('KinFaceW-II', 'ms', 5),\n",
    "            ('KinFaceW-II', 'md', 5)]\n",
    "\n",
    "nu_values = np.arange(0.05, 1.0, 0.05)\n",
    "max_depth_values = [max_depth for max_depth in range(10, 16)]\n",
    "n_estimators_values = [n_estimators for n_estimators in range(1, 6)]\n",
    "for (dataset, kinship, n_fold) in datasets:\n",
    "    print(dataset, kinship)\n",
    "    svm_accu_grid = np.zeros(len(nu_values), dtype=np.float32)\n",
    "    rdf_accu_grid = np.zeros((len(max_depth_values), len(n_estimators_values)), dtype=np.float32)\n",
    "    for fold in range(n_fold):\n",
    "        ((P0, C0, K0), (P1, C1, K1)) = load_fold(rootdir, dataset, kinship, fold+1)\n",
    "\n",
    "        NMD0 = get_nmd(P0, C0, 15)\n",
    "        NMD1 = get_nmd(P1, C1, 15)\n",
    "\n",
    "\n",
    "        for i, nu in enumerate(nu_values):\n",
    "            model = svm.NuSVC(nu=nu, kernel=\"rbf\", verbose=False, gamma=\"auto\")\n",
    "            model.fit(NMD0, K0)\n",
    "            accuracy = model.score(NMD1, K1)\n",
    "            svm_accu_grid[i] = svm_accu_grid[i] + accuracy\n",
    "            \n",
    "        for i, max_depth in enumerate(max_depth_values):\n",
    "            for j, n_estimators in enumerate(n_estimators_values):\n",
    "                best_accu = 0.0\n",
    "                for _ in range(5):\n",
    "                    model = ensemble.RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=1)\n",
    "                    model.fit(NMD0, K0)\n",
    "                    accuracy = model.score(NMD1, K1)\n",
    "                    if accuracy > best_accu:\n",
    "                        best_accu = accuracy\n",
    "                rdf_accu_grid[i, j] = rdf_accu_grid[i, j] + best_accu\n",
    "\n",
    "    best_nu = 0\n",
    "    best_accu = 0\n",
    "    for i, nu in enumerate(nu_values):\n",
    "        if svm_accu_grid[i] > best_accu:\n",
    "            best_accu = svm_accu_grid[i]\n",
    "            best_nu = nu\n",
    "    \n",
    "    print('SVM: %.02f%% [nu: %g]'%(100*best_accu/n_fold, best_nu))\n",
    "    \n",
    "    best_d = 0\n",
    "    best_n = 0\n",
    "    best_a = 0\n",
    "    for i, max_depth in enumerate(max_depth_values):\n",
    "        for j, n_estimators in enumerate(n_estimators_values):\n",
    "            if rdf_accu_grid[i, j]>best_a:\n",
    "                best_d = max_depth\n",
    "                best_n = n_estimators\n",
    "                best_a = rdf_accu_grid[i, j]\n",
    "    \n",
    "    print('RandomForest: %.02f%% [max_depth: %d] [n_estimators: %d]'%(100*best_a/n_fold, best_d, best_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
